import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
from tqdm import tqdm
from muelder_optimise import MyModel
from muelder_custom_cv import CustomCV
from muelder_error import error
from muelder_error import data_municipality

def load_data(filepath):
    # Load data
    data = pd.read_csv(filepath, index_col=0, header=None)  # No header for the first column
    return data

from muelder_custom_cv import CustomCV

def custom_cross_val_score(model, X, y, cv, error_func, params, data_municipality):
    custom_cv = CustomCV(n_splits=cv)
    scores = []

    for train_index, test_index in custom_cv.split(X):
        try:
            X_train, X_test = X[train_index], X[test_index]
            y_train, y_test = y[train_index], y[test_index]
        except IndexError:
            print("IndexError: Ensure that the indices generated by CustomCV.split() are valid for the dimensions of X and y.")
            return None

        model.set_params(**params)
        model.fit(X_train, y_train)

        predictions = model.predict(X_test)

        if len(data_municipality) == 0:
            print("Skipping error computation as data_municipality is empty.")
            continue

        score = error_func(predictions, data_municipality)
        scores.append(score)

    return np.array(scores)

if __name__ == '__main__':
    # Define the path to data file
    filepath = 'solar_pv_training_data.csv'

    # Set working directory
    os.chdir(os.path.dirname(os.path.realpath(__file__)))

    # Load training data
    data = load_data(filepath)

    # Extract features (X) and target (y)
    X = data.iloc[:, 1:]  # Exclude the first column (municipality names)
    y = data.iloc[:, -1]  # Assuming the last column is the target year, modify as needed

    model = MyModel()  # Initialize MyModel without specifying initial values

    # Define a range for n_splits
    n_splits_range = list(range(2, 3))

    # Lists to store the mean cross-validated score for each value of n_splits
    cv_scores_mean = []
    cv_scores_std = []

    # Params for the model, adjust as per your model parameters
    default_params = {
        "weight_eco": 0.6,
        "weight_env": 0.6,
        "weight_cof": 0.6,
        "weight_soc": 0.6,
    }

    # Loop over n_splits_range and for each value, perform cross-validation and then compute the mean score
    for n_splits in tqdm(n_splits_range):
        params = default_params.copy()  # Make a copy of default_params
        cv_scores_fold = []  # List to store scores for each fold

        # Perform cross-validation for the current number of splits
        cv_scores = custom_cross_val_score(model, X.values, y.values, cv=n_splits, error_func=error, params=params, data_municipality=data_municipality)
        
        cv_scores_mean.append(np.mean(cv_scores))
        cv_scores_std.append(np.std(cv_scores))

    cv_scores_mean = np.array(cv_scores_mean)
    cv_scores_std = np.array(cv_scores_std)

    # Plot the validation curve
    plt.figure(figsize=(10, 6))
    plt.plot(n_splits_range, cv_scores_mean, color='blue', marker='o', markersize=5, label='mean cross-validated error')
    plt.fill_between(n_splits_range, cv_scores_mean - cv_scores_std, cv_scores_mean + cv_scores_std, alpha=0.15, color='blue')
    plt.title('Validation curve')
    plt.xlabel('n_splits')
    plt.ylabel('Cross-validated error')
    plt.grid()
    plt.legend(loc='upper right')

    min_mean_idx = np.argmin(cv_scores_mean) # Find index where mean score is minimum
    optimal_n_splits = n_splits_range[min_mean_idx] # Find the n_splits value corresponding to this index
    std_at_min_mean = cv_scores_std[min_mean_idx] # Fetch the standard deviation corresponding to this minimum mean
    
    print(f"The optimal number of splits is: {optimal_n_splits}")
    print(f"The error at this split is: {cv_scores_mean[min_mean_idx]}")
    print(f"The standard deviation at this split is: {std_at_min_mean}")
    
    plt.show()
